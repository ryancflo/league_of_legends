[2022-05-20 03:06:06,560] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: league_of_legends_dag.paths.path_champions.azure_champions_snowflake manual__2022-05-20T01:19:49.642146+00:00 [queued]>
[2022-05-20 03:06:06,570] {taskinstance.py:1037} INFO - Dependencies all met for <TaskInstance: league_of_legends_dag.paths.path_champions.azure_champions_snowflake manual__2022-05-20T01:19:49.642146+00:00 [queued]>
[2022-05-20 03:06:06,570] {taskinstance.py:1243} INFO - 
--------------------------------------------------------------------------------
[2022-05-20 03:06:06,571] {taskinstance.py:1244} INFO - Starting attempt 3 of 4
[2022-05-20 03:06:06,571] {taskinstance.py:1245} INFO - 
--------------------------------------------------------------------------------
[2022-05-20 03:06:06,580] {taskinstance.py:1264} INFO - Executing <Task(AzureDataLakeToSnowflakeTransferOperator): paths.path_champions.azure_champions_snowflake> on 2022-05-20 01:19:49.642146+00:00
[2022-05-20 03:06:06,585] {standard_task_runner.py:52} INFO - Started process 366 to run task
[2022-05-20 03:06:06,587] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'league_of_legends_dag', 'paths.path_champions.azure_champions_snowflake', 'manual__2022-05-20T01:19:49.642146+00:00', '--job-id', '476', '--raw', '--subdir', 'DAGS_FOLDER/dataDragon_dag.py', '--cfg-path', '/tmp/tmp3vtze7p0', '--error-file', '/tmp/tmpo5d83ur5']
[2022-05-20 03:06:06,587] {standard_task_runner.py:77} INFO - Job 476: Subtask paths.path_champions.azure_champions_snowflake
[2022-05-20 03:06:06,628] {logging_mixin.py:109} INFO - Running <TaskInstance: league_of_legends_dag.paths.path_champions.azure_champions_snowflake manual__2022-05-20T01:19:49.642146+00:00 [running]> on host ca9a242fab95
[2022-05-20 03:06:06,667] {taskinstance.py:1429} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=admin
AIRFLOW_CTX_DAG_ID=league_of_legends_dag
AIRFLOW_CTX_TASK_ID=paths.path_champions.azure_champions_snowflake
AIRFLOW_CTX_EXECUTION_DATE=2022-05-20T01:19:49.642146+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-05-20T01:19:49.642146+00:00
[2022-05-20 03:06:06,668] {azureToSnowflake.py:73} INFO - Executing COPY command...
[2022-05-20 03:06:06,678] {connection.py:257} INFO - Snowflake Connector for Python Version: 2.5.1, Python Version: 3.8.12, Platform: Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.2.5
[2022-05-20 03:06:06,678] {connection.py:868} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2022-05-20 03:06:06,679] {connection.py:886} INFO - Setting use_openssl_only mode to False
[2022-05-20 03:06:07,420] {cursor.py:637} INFO - query: [ALTER SESSION SET autocommit=True]
[2022-05-20 03:06:07,544] {cursor.py:661} INFO - query execution done
[2022-05-20 03:06:07,545] {snowflake.py:324} INFO - Running statement: COPY INTO STAGING_DATADRAGON_CHAMPIONS
FROM @MY_AZURE_DATADRAGON_CHAMPIONS_STAGE/
files=('datadragon-champions/2022/5/20/3.json')
file_format=DATADRAGON_FILEFORMAT, parameters: None
[2022-05-20 03:06:07,545] {cursor.py:637} INFO - query: [COPY INTO STAGING_DATADRAGON_CHAMPIONS FROM @MY_AZURE_DATADRAGON_CHAMPIONS_STAGE...]
[2022-05-20 03:06:07,709] {cursor.py:661} INFO - query execution done
[2022-05-20 03:06:07,714] {connection.py:499} INFO - closed
[2022-05-20 03:06:07,760] {connection.py:502} INFO - No async queries seem to be running, deleting session
[2022-05-20 03:06:07,864] {taskinstance.py:1718} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/opt/airflow/plugins/custom_transfers/azureToSnowflake.py", line 74, in execute
    snowflake_hook.run(copy_query, self.autocommit)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 328, in run
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 721, in execute
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 258, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 188, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 091003 (22000): 01a4623a-0000-f1b3-0000-d9690003736a: Failure using stage area. Cause: [If you are using a StorageSharedKeyCredential, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate method call.
If you are using a SAS token, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate generateSas method call.
Please remember to disable 'Azure-Storage-Log-String-To-Sign' before going to production as this string can potentially contain PII.
Status code 403, (empty body) (Status Code: 403; Error Code: AuthenticationFailed)]
[2022-05-20 03:06:07,876] {taskinstance.py:1272} INFO - Marking task as UP_FOR_RETRY. dag_id=league_of_legends_dag, task_id=paths.path_champions.azure_champions_snowflake, execution_date=20220520T011949, start_date=20220520T030606, end_date=20220520T030607
[2022-05-20 03:06:07,890] {standard_task_runner.py:89} ERROR - Failed to execute job 476 for task paths.path_champions.azure_champions_snowflake
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 180, in _run_raw_task
    ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1334, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1460, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1516, in _execute_task
    result = execute_callable(context=context)
  File "/opt/airflow/plugins/custom_transfers/azureToSnowflake.py", line 74, in execute
    snowflake_hook.run(copy_query, self.autocommit)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 328, in run
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 721, in execute
    Error.errorhandler_wrapper(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 258, in errorhandler_wrapper
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 188, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 091003 (22000): 01a4623a-0000-f1b3-0000-d9690003736a: Failure using stage area. Cause: [If you are using a StorageSharedKeyCredential, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate method call.
If you are using a SAS token, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate generateSas method call.
Please remember to disable 'Azure-Storage-Log-String-To-Sign' before going to production as this string can potentially contain PII.
Status code 403, (empty body) (Status Code: 403; Error Code: AuthenticationFailed)]
[2022-05-20 03:06:07,924] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-05-20 03:06:07,958] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
